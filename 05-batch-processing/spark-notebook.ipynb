{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import types, functions as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "25/02/27 20:48:18 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = SparkSession.builder\\\n",
    "          .master(\"local[*]\")\\\n",
    "          .appName(\"test\")\\\n",
    "          .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = types.StructType([\n",
    "  types.StructField('hvfhs_license_num', types.StringType(), True),\n",
    "  types.StructField('dispatching_base_num', types.StringType(), True),\n",
    "  types.StructField('originating_base_num', types.StringType(), True),\n",
    "  types.StructField('request_datetime', types.TimestampNTZType(), True),\n",
    "  types.StructField('on_scene_datetime', types.TimestampNTZType(), True),\n",
    "  types.StructField('pickup_datetime', types.TimestampNTZType(), True),\n",
    "  types.StructField('dropoff_datetime', types.TimestampNTZType(), True),\n",
    "  types.StructField('PULocationID', types.IntegerType(), True),\n",
    "  types.StructField('DOLocationID', types.IntegerType(), True),\n",
    "  types.StructField('trip_miles', types.DoubleType(), True),\n",
    "  types.StructField('trip_time', types.IntegerType(), True),\n",
    "  types.StructField('base_passenger_fare', types.DoubleType(), True),\n",
    "  types.StructField('tolls', types.DoubleType(), True),\n",
    "  types.StructField('bcf', types.DoubleType(), True),\n",
    "  types.StructField('sales_tax', types.DoubleType(), True),\n",
    "  types.StructField('congestion_surcharge', types.DoubleType(), True),\n",
    "  types.StructField('airport_fee', types.DoubleType(), True),\n",
    "  types.StructField('tips', types.DoubleType(), True),\n",
    "  types.StructField('driver_pay', types.DoubleType(), True),\n",
    "  types.StructField('shared_request_flag', types.StringType(), True),\n",
    "  types.StructField('shared_match_flag', types.StringType(), True),\n",
    "  types.StructField('access_a_ride_flag', types.StringType(), True),\n",
    "  types.StructField('wav_request_flag', types.StringType(), True),\n",
    "  types.StructField('wav_match_flag', types.StringType(), True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df = spark.read\\\n",
    "      .option(\"header\", True)\\\n",
    "      .parquet('fhvhv_tripdata_2021-01.parquet')\n",
    "      # .schema(schema)\\\n",
    "      # .option('mergeSchema', True)\\"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- hvfhs_license_num: string (nullable = true)\n",
      " |-- dispatching_base_num: string (nullable = true)\n",
      " |-- originating_base_num: string (nullable = true)\n",
      " |-- request_datetime: timestamp_ntz (nullable = true)\n",
      " |-- on_scene_datetime: timestamp_ntz (nullable = true)\n",
      " |-- pickup_datetime: timestamp_ntz (nullable = true)\n",
      " |-- dropoff_datetime: timestamp_ntz (nullable = true)\n",
      " |-- PULocationID: long (nullable = true)\n",
      " |-- DOLocationID: long (nullable = true)\n",
      " |-- trip_miles: double (nullable = true)\n",
      " |-- trip_time: long (nullable = true)\n",
      " |-- base_passenger_fare: double (nullable = true)\n",
      " |-- tolls: double (nullable = true)\n",
      " |-- bcf: double (nullable = true)\n",
      " |-- sales_tax: double (nullable = true)\n",
      " |-- congestion_surcharge: double (nullable = true)\n",
      " |-- airport_fee: double (nullable = true)\n",
      " |-- tips: double (nullable = true)\n",
      " |-- driver_pay: double (nullable = true)\n",
      " |-- shared_request_flag: string (nullable = true)\n",
      " |-- shared_match_flag: string (nullable = true)\n",
      " |-- access_a_ride_flag: string (nullable = true)\n",
      " |-- wav_request_flag: string (nullable = true)\n",
      " |-- wav_match_flag: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.repartition(24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "25/02/27 20:48:32 WARN GarbageCollectionMetrics: To enable non-built-in garbage collector(s) List(G1 Concurrent GC), users should configure it(them) to spark.eventLog.gcMetrics.youngGenerationGarbageCollectors or spark.eventLog.gcMetrics.oldGenerationGarbageCollectors\n",
      "25/02/27 20:49:17 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/02/27 20:49:21 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/02/27 20:49:24 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "25/02/27 20:49:25 WARN MemoryManager: Total allocation exceeds 95.00% (1,020,054,720 bytes) of heap memory\n",
      "Scaling row group sizes to 95.00% for 8 writers\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df.write.parquet('fhvhv/2021/01', mode='overwrite')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_func(base_num):\n",
    "  num = int(base_num[1:])\n",
    "  if num % 7 == 0:\n",
    "    return f's/{num:0.3x}'\n",
    "  else:\n",
    "    return f'e/{num:0.3x}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_func_udf = F.udf(custom_func, returnType=types.StringType())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+------------+------------+------------+\n",
      "|pickup_date|dropoff_date|PULocationID|DOLocationID|\n",
      "+-----------+------------+------------+------------+\n",
      "| 2021-01-26|  2021-01-26|         247|         200|\n",
      "| 2021-01-29|  2021-01-29|          61|         119|\n",
      "| 2021-01-27|  2021-01-27|         248|         182|\n",
      "| 2021-01-04|  2021-01-04|         225|          97|\n",
      "| 2021-01-25|  2021-01-25|         233|         140|\n",
      "| 2021-01-15|  2021-01-15|          20|         265|\n",
      "| 2021-01-23|  2021-01-23|         137|         226|\n",
      "| 2021-01-20|  2021-01-20|         126|         254|\n",
      "| 2021-01-22|  2021-01-22|          50|         166|\n",
      "| 2021-01-01|  2021-01-01|          28|         129|\n",
      "| 2021-01-23|  2021-01-23|          68|         265|\n",
      "| 2021-01-28|  2021-01-28|          28|         134|\n",
      "| 2021-01-15|  2021-01-15|         159|          18|\n",
      "| 2021-01-05|  2021-01-05|          37|         256|\n",
      "| 2021-01-04|  2021-01-04|          35|         177|\n",
      "| 2021-01-17|  2021-01-17|          85|          35|\n",
      "| 2021-01-30|  2021-01-30|         240|          82|\n",
      "| 2021-01-30|  2021-01-30|         226|         142|\n",
      "| 2021-01-13|  2021-01-13|         254|          51|\n",
      "| 2021-01-06|  2021-01-06|         126|         126|\n",
      "+-----------+------------+------------+------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df\\\n",
    "  .withColumn('pickup_date', F.to_date(df.pickup_datetime))\\\n",
    "  .withColumn('dropoff_date', F.to_date(df.dropoff_datetime))\\\n",
    "  .withColumn('base_id', custom_func_udf(df.dispatching_base_num))\\\n",
    "  .select('pickup_date', 'dropoff_date', 'PULocationID', 'DOLocationID')\\\n",
    "  .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[pickup_datetime: timestamp_ntz, dropoff_datetime: timestamp_ntz, PULocationID: bigint, DOLocationID: bigint]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select('pickup_datetime', 'dropoff_datetime', 'PULocationID', 'DOLocationID')\\\n",
    "    .filter(df.hvfhs_license_num == 'HV0003')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
